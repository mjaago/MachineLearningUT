{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6 part 1 - Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>To install `hmmlearn` run the following command: `conda install -c omnia hmmlearn` (recommended) or alternatively: `pip install hmmlearn`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Hidden Markov Models (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is about a corrupt casino which uses two dice - one is fair and the other one is loaded. The fair one gives results 0,1,2,3,4,5 all with equal probability $1/6$ while the loaded one gives 5 with probability 0.50 and 0 with probability 0.02, whereas all other results 1,2,3,4 are equally probable, that is with probability 0.12 (the probabilities nicely add up $0.50+0.02+4\\cdot 0.12=1.0$). As a sidenote, of course, dice have usually scores 1,2,3,4,5,6 but for simpler programming we are using 0,1,2,3,4,5 instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The casino dealer uniformly randomly chooses one of the two dice (with probability 0.5 chooses fair, with probability 0.5 chooses loaded) and throws it. After this the dealer changes to the other dice with probability 0.1 and stays with the same one with probability 0.9. The chosen dice is thrown and again the dice is changed to the other one with probability 0.1. This continues for 300 throws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given the results of these 300 throws and your task is to guess which of the two dice was used during each throw - the fair or the loaded one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='purple'>(a) Create the HMM model by filling in the following code, with 0 and 1 corresponding to fair and loaded dice, respectively. Using the existing commands generate the test data for yourself. Print out the results from dice and the truth about each throw regarding whether the dice has been loaded or not.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [0]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [3]\n",
      " [3]\n",
      " [5]\n",
      " [4]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [4]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [4]\n",
      " [4]\n",
      " [1]\n",
      " [0]\n",
      " [5]\n",
      " [4]\n",
      " [4]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [5]\n",
      " [3]\n",
      " [3]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [3]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [3]\n",
      " [3]\n",
      " [2]\n",
      " [2]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [3]\n",
      " [5]\n",
      " [3]\n",
      " [0]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [5]\n",
      " [0]\n",
      " [3]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [3]\n",
      " [2]\n",
      " [5]\n",
      " [4]\n",
      " [2]\n",
      " [2]\n",
      " [4]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [5]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [2]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [2]\n",
      " [1]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [1]\n",
      " [4]\n",
      " [2]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [3]\n",
      " [1]\n",
      " [5]\n",
      " [4]\n",
      " [3]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [0]\n",
      " [2]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [3]\n",
      " [4]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [4]\n",
      " [2]\n",
      " [4]\n",
      " [4]\n",
      " [4]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [5]\n",
      " [0]\n",
      " [3]\n",
      " [4]\n",
      " [0]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [5]\n",
      " [3]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [3]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [1]\n",
      " [3]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [5]\n",
      " [3]\n",
      " [5]\n",
      " [2]\n",
      " [3]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [3]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [4]\n",
      " [3]\n",
      " [5]\n",
      " [5]\n",
      " [3]\n",
      " [5]\n",
      " [3]\n",
      " [4]\n",
      " [2]\n",
      " [5]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [4]\n",
      " [5]\n",
      " [3]\n",
      " [3]\n",
      " [0]\n",
      " [5]\n",
      " [3]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [4]\n",
      " [3]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [5]\n",
      " [5]\n",
      " [3]\n",
      " [5]\n",
      " [2]\n",
      " [5]]\n",
      "[1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from hmmlearn.hmm import MultinomialHMM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "hmm = MultinomialHMM(n_components = 2, init_params=\"\", random_state=0)\n",
    "\n",
    "hmm.startprob_ = [0.5, 0.5]\n",
    "hmm.transmat_ = [[0.9, 0.1], [0.1, 0.9]]\n",
    "hmm.emissionprob_ = [[1/6, 1/6, 1/6, 1/6, 1/6, 1/6], [0.02, 0.12, 0.12, 0.12, 0.12, 0.5]]\n",
    "\n",
    "generated_test_data = hmm.sample(300)\n",
    "dice_results = generated_test_data[0]\n",
    "fair_or_loaded = generated_test_data[1]\n",
    "print(dice_results)\n",
    "print(fair_or_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='purple'>(b) Next your goal is to learn for each throw whether the dice has been loaded or not. First, let us treat all throwing results as independent. In this case there is a single feature (a single result 0-5 from a dice) and a binary label (the dice is loaded or fair). In this scenario, what would the Bayes-optimal model predict for result 0? 1? 2? 3? 4? 5?</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a roll of  0  we predict:  Fair dice\n",
      "For a roll of  1  we predict:  Fair dice\n",
      "For a roll of  2  we predict:  Fair dice\n",
      "For a roll of  3  we predict:  Fair dice\n",
      "For a roll of  4  we predict:  Fair dice\n",
      "For a roll of  5  we predict:  Loaded dice\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "loaded_prob, fair_prob = [0.02, 0.12, 0.12, 0.12, 0.12, 0.5], [1/6, 1/6, 1/6, 1/6, 1/6, 1/6]\n",
    "labels = [\"Loaded dice\", \"Fair dice\"]\n",
    "\n",
    "def argmax(items):\n",
    "  return items.index(max(items))\n",
    "\n",
    "for i in range(6):\n",
    "    print(\"For a roll of \", i , \" we predict: \", labels[argmax([loaded_prob[i], fair_prob[i]])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='purple'>(c) Let us consider the model which for result 5 predicts that the dice is loaded and for any other result it predicts that it is fair. Calculate and report the accuracy of such a model on data dice_results, where the true labels are in fair_or_loaded.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  0.59\n"
     ]
    }
   ],
   "source": [
    "class o_model():\n",
    "    \n",
    "    def predict(self, data):\n",
    "        preds = []\n",
    "        for i in data:\n",
    "            if i == 5:\n",
    "                preds.append(1)\n",
    "            else:\n",
    "                preds.append(0)\n",
    "        return preds\n",
    "        \n",
    "pred = o_model().predict(dice_results)\n",
    "print(\"The accuracy is: \", (pred == fair_or_loaded).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='purple'>(d) Apply Viterbi algorithm to find out what the most likely sequence of loaded/fair dice is for these dice_results data. Explain what logprob means (logarithm of what probability?)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-529.6194906731442\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "logprob,most_likely_seq = hmm.decode(dice_results, algorithm = \"viterbi\")\n",
    "print(logprob)\n",
    "print(most_likely_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The logprob is the logarithm of the probability that this is the true sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='purple'>(e) Calculate and report the accuracy of predictions using Viterbi algorithm. Which of the methods in (c) and (d) was more accurate? Why?</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  0.653333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy is: \", (most_likely_seq == fair_or_loaded).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The Viterbi algorithm is more accurate, since it most probably uses conditional probabilities to calculate the sequence instead of saying that we have independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='purple'>(f) Calculate and report the probability that fair dice was used all the time (and the loaded dice was not used) and that the results of throws are exactly the same as dice_results.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability would be:  3.36006532651e-248\n"
     ]
    }
   ],
   "source": [
    "print(\"The probability would be: \", 0.5 * np.power(0.9, len(dice_results)) * np.power(1/6, len(dice_results)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='purple'>(g) Now calculate and report the joint probability that the loaded dice was used all the time (and the fair dice was not used) and that the results of throws are exactly the same as dice_results.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability would be:  2.7861933138e-244\n"
     ]
    }
   ],
   "source": [
    "print(\"The probability would be: \", (0.5 * np.power(0.9, len(dice_results)) * np.power(0.5, sum(dice_results == 5)) *\n",
    "     np.power(0.02, sum(dice_results == 0)) * np.power(0.12, sum((dice_results > 0) & (dice_results < 5))))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='purple'>(h) Finally, calculate and report the joint probability that the loaded and fair dice were used exactly in the order given in most_likely_seq and that the results of throws are exactly the same as dice_results. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.75388637817134e-231\n"
     ]
    }
   ],
   "source": [
    "last = -1\n",
    "prob = 1.0\n",
    "for dice, result in zip(most_likely_seq, dice_results):\n",
    "    result = result[0]\n",
    "    if (last == -1):\n",
    "        prob = prob * 0.5\n",
    "    elif (last == dice):\n",
    "        prob = prob * 0.9\n",
    "    else:\n",
    "        prob = prob * 0.1\n",
    "        \n",
    "    if dice == 0:\n",
    "        prob = prob * fair_prob[result]\n",
    "    else:\n",
    "        prob = prob * loaded_prob[result]\n",
    "    last = dice\n",
    "        \n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='purple'>(i) Compare the probabilities calculated in (f), (g) and (h). Which of the probabilities is the highest and how does the logarithm of this probability relate to the results in subtask (d)?</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    The last probability is the highest, which is also logical. The logarithm of subtask (d) is exactly the same probability that we got in the last subtask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## How long did it take you to solve this task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please answer as precisely as you can. It does not affect your points or grade in any way. It is okey, if it took 30 minutes or 24 hours. The results are used to improve the homeworks next year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Task 1:</font>** $2$ hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Please use <b>\"Kernel->Restart and Run All\"</b> command in Jupyter Notebook before submitting the homework and check your results. This ensures that we would be able to replicate your results while grading.</font>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "GP_homework.ipynb",
   "provenance": [
    {
     "file_id": "1ErGnde5ccK3pBDTe_Je4CWY9_F_JLnOd",
     "timestamp": 1526982392789
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
